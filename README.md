
# Olist Data Pipeline

This project implements a scalable data pipeline for the Olist Brazilian e-commerce dataset, facilitating efficient data ingestion, transformation, and preparation for analytics and reporting.

## ğŸ“Œ Overview

The pipeline is designed to:

- Ingest data from multiple sources, including Https, MySQL and MongoDB.
- Transform and clean data using Databricks(PySpark)/Python scripts.
- Orchestrate workflows with Azure Data Factory.
- Prepare data for downstream analytics and visualization tools.

## ğŸ—‚ï¸ Repository Structure

```
.
â”œâ”€â”€ AzureDataFactory/             # Azure Data Factory pipeline definitions
â”œâ”€â”€ Data/                         # Sample datasets and raw input files
â”œâ”€â”€ DataIngestionPipeline.png     # Visual representation of the pipeline architecture
â”œâ”€â”€ databricks_transformation.py  # Data transformation logic using PySpark
â”œâ”€â”€ mongodb_data_ingestion.py     # Script to ingest data into MongoDB
â”œâ”€â”€ mysql_data_ingestion.py       # Script to ingest data into MySQL
â”œâ”€â”€ relative_urls.json            # Configuration file for relative URLs
â”œâ”€â”€ requirements.txt              # Python dependencies
â”œâ”€â”€ transformation.ipynb          # Data transformation logic using Python
â””â”€â”€ README.md                     # Project documentation
```

## ğŸ”§ Technologies Used

- **Data Sources**: MySQL, MongoDB
- **Data Processing**: Databricks (PySpark), Python
- **Orchestration**: Azure

## ğŸ“ˆ Data Flow Diagram

![Data Pipeline Architecture](DataIngestionPipeline.png)

## ğŸ§± Data Schema

![Data Schema](olist-data-schema.png)

---

For more information on the Olist dataset, visit the [Kaggle page](https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce).